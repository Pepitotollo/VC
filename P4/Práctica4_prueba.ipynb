{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carga del modelo\n",
    "model = YOLO('yolo11n.pt')  # Contenedores\n",
    "# model = YOLO('yolov11n-seg.pt')  # Máscaras\n",
    "# model = YOLO('yolo11n-pose.pt')  # Pose\n",
    "\n",
    "# Para un vídeo \n",
    "filename = \"videoplayback.mp4\"\n",
    "results = model.track(source=filename, stream=True)  # Usamos 'stream=True' para obtener los frames uno a uno\n",
    "\n",
    "# Inicialización de la ventana y reproducción de frames\n",
    "for result in results:\n",
    "    frame = result.orig_img  # Obtener el frame original del resultado\n",
    "\n",
    "    # Dibujar las detecciones en el frame\n",
    "    if result.boxes is not None:  # Verifica si hay detecciones\n",
    "        for box in result.boxes:  # Accede a cada caja detectada\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Coordenadas de la caja\n",
    "            label = box.cls  # Clase de la detección\n",
    "            confidence = box.conf.item()  # Convierte la confianza a número de punto flotante\n",
    "\n",
    "            # Texto de la etiqueta con la confianza\n",
    "            text = f\"{model.names[int(label)]} {confidence:.2f}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Dibujar la caja en verde\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # Dibujar el texto\n",
    "\n",
    "    # Redimensionar el frame y mostrarlo\n",
    "    frame_resized = cv2.resize(frame, (960, 540))  # Ajustar el tamaño de la ventana\n",
    "    cv2.imshow(\"Video Resized\", frame_resized)\n",
    "\n",
    "    # Detener la ejecución si se presiona la tecla Escape\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Definir la ubicación del archivo YAML de datos\n",
    "data_yaml_path = 'C:/Users/noelp/anaconda3/envs/VC_P4/miarchivo.yml'  # Cambia esto a la ruta de tu archivo YAML\n",
    "\n",
    "# Cargar un modelo YOLOv8 base para entrenar desde cero\n",
    "model = YOLO('yolov8n.yaml')  # Puedes usar el archivo de configuración de modelo YOLOv8\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model.train(data=data_yaml_path, imgsz=416, batch=4, device='cpu', epochs=40, name=\"entrenamiento_definitivo\")  # Nombre personalizado para el archivo de salida\n",
    "\n",
    "print(\"Entrenamiento completo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "video 1/1 (frame 1/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 51.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 2/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 46.2ms\n",
      "\n",
      "0: 256x416 2 Platess, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 3/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 45.0ms\n",
      "\n",
      "0: 256x416 2 Platess, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 4/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 43.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 5/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 45.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 6/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 42.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 7/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 41.0ms\n",
      "\n",
      "0: 256x416 2 Platess, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 8/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 45.0ms\n",
      "\n",
      "0: 256x416 2 Platess, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 9/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 43.9ms\n",
      "\n",
      "0: 256x416 1 Plates, 21.3ms\n",
      "Speed: 1.0ms preprocess, 21.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 10/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 40.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 11/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 42.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 12/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 43.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 13/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 45.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 14/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 47.8ms\n",
      "\n",
      "0: 256x416 1 Plates, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 15/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 46.6ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.7ms\n",
      "Speed: 1.0ms preprocess, 24.7ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 16/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 45.5ms\n",
      "\n",
      "0: 256x416 1 Plates, 24.3ms\n",
      "Speed: 1.0ms preprocess, 24.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 17/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 45.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 18/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 40.1ms\n",
      "\n",
      "0: 256x416 1 Plates, 22.8ms\n",
      "Speed: 1.0ms preprocess, 22.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 19/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 42.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 20/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 42.0ms\n",
      "\n",
      "0: 256x416 1 Plates, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 21/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 41.2ms\n",
      "\n",
      "0: 256x416 1 Plates, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 22/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 44.9ms\n",
      "\n",
      "0: 256x416 (no detections), 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 23/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 40.3ms\n",
      "\n",
      "0: 256x416 (no detections), 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 24/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 39.0ms\n",
      "\n",
      "0: 256x416 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 25/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 42.0ms\n",
      "\n",
      "0: 256x416 (no detections), 23.9ms\n",
      "Speed: 1.0ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "video 1/1 (frame 26/2950) c:\\Users\\noelp\\anaconda3\\envs\\VC_P4\\video.mp4: 384x640 1 car, 43.7ms\n",
      "\n",
      "0: 256x416 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_general = YOLO('yolo11n.pt')  # Modelo para detección de coches y personas\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model_path = \"C:/Users/noelp/anaconda3/envs/VC_P4/runs/detect/entrenamiento_definitivo/weights/best.pt\"  # Ruta corregida\n",
    "model_plates = YOLO(model_path)\n",
    "\n",
    "# Para un vídeo o imagen\n",
    "filename = \"video.mp4\"  # Cambia esto al nombre de tu archivo de vídeo\n",
    "#filename = \"videoplayback.mp4\"\n",
    "results_stream = model_general.track(source=filename, stream=True)\n",
    "\n",
    "# Inicialización de la ventana y reproducción de frames\n",
    "for result in results_stream:\n",
    "    frame = result.orig_img  # Obtener el frame original del resultado\n",
    "\n",
    "    # Detección de coches y personas en el frame\n",
    "    if result.boxes is not None:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Coordenadas de la caja\n",
    "            label = model_general.names[int(box.cls)]  # Obtiene el nombre de la clase\n",
    "            confidence = box.conf.item()  # Convierte la confianza a número de punto flotante\n",
    "\n",
    "            # Mostrar solo coches y personas\n",
    "            if label in ['car', 'person']:\n",
    "                text = f\"{label} {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Dibujar la caja en verde\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # Dibujar el texto\n",
    "\n",
    "    # Realizar la detección de matrículas en el mismo frame\n",
    "    results_plates = model_plates(frame)  # Procesa el frame con tu modelo de matrículas\n",
    "    for result_plates in results_plates:\n",
    "        if result_plates.boxes is not None:\n",
    "            for box in result_plates.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])  # Coordenadas de la caja\n",
    "                label = model_plates.names[int(box.cls)]  # Obtiene el nombre de la clase\n",
    "                confidence = box.conf.item()  # Convierte la confianza a número de punto flotante\n",
    "\n",
    "                # Asumimos que tu modelo detecta matrículas, ajusta el nombre de la clase si es necesario\n",
    "                text = f\"{label} {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Dibujar la caja en azul\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Dibujar el texto\n",
    "\n",
    "    # Redimensionar el frame y mostrarlo\n",
    "    frame_resized = cv2.resize(frame, (960, 540))  # Ajustar el tamaño de la ventana\n",
    "    cv2.imshow(\"Video Resized\", frame_resized)\n",
    "\n",
    "    # Detener la ejecución si se presiona la tecla Escape\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
