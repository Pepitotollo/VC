{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carga del modelo\n",
    "model = YOLO('yolo11n.pt')  # Contenedores\n",
    "\n",
    "# Para un vídeo \n",
    "filename = \"videoplayback.mp4\"\n",
    "results = model.track(source=filename, stream=True)  # Usamos 'stream=True' para obtener los frames uno a uno\n",
    "\n",
    "# Inicialización de la ventana y reproducción de frames\n",
    "for result in results:\n",
    "    frame = result.orig_img  # Obtener el frame original del resultado\n",
    "\n",
    "    # Dibujar las detecciones en el frame\n",
    "    if result.boxes is not None:  # Verifica si hay detecciones\n",
    "        for box in result.boxes:  # Accede a cada caja detectada\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Coordenadas de la caja\n",
    "            label = box.cls  \n",
    "            confidence = box.conf.item()  \n",
    "\n",
    "            # Texto de la etiqueta \n",
    "            text = f\"{model.names[int(label)]} {confidence:.2f}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Dibujar la caja en verde\n",
    "            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # Dibujar el texto\n",
    "\n",
    "    # Redimensionar el frame y mostrarlo\n",
    "    frame_resized = cv2.resize(frame, (960, 540))  # Ajustar el tamaño de la ventana\n",
    "    cv2.imshow(\"Video Resized\", frame_resized)\n",
    "\n",
    "    # Detener la ejecución si se presiona la tecla Escape\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Definir la ubicación del archivo YAML de datos\n",
    "data_yaml_path = 'C:/Users/joele/anaconda3/envs/VC_P4/miarchivo.yml'  # Cambia esto a la ruta de tu archivo YAML\n",
    "\n",
    "# Cargar un modelo YOLOv8 base para entrenar desde cero\n",
    "model = YOLO('yolov8n.yaml')  # Puedes usar el archivo de configuración de modelo YOLOv8\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model.train(data=data_yaml_path, imgsz=416, batch=4, device='cpu', epochs=40, name=\"entrenamiento_definitivo\")  # Nombre personalizado para el archivo de salida\n",
    "\n",
    "print(\"Entrenamiento completo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Crear un lector de EasyOCR\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "model_general = YOLO('yolo11n.pt')\n",
    "model_path = \"C:/Users/noelp/anaconda3/envs/VC_P4/runs/detect/entrenamiento_definitivo/weights/best.pt\"\n",
    "model_plates = YOLO(model_path)\n",
    "\n",
    "# Para un vídeo o imagen\n",
    "filename = \"video.mp4\"\n",
    "results_stream = model_general.track(source=filename, stream=True)\n",
    "\n",
    "# Inicialización de la lista para los resultados\n",
    "results_list = []\n",
    "frame_count = 0\n",
    "\n",
    "# Inicialización de contadores\n",
    "total_cars = 0\n",
    "total_people = 0\n",
    "\n",
    "# Diccionarios para rastrear objetos\n",
    "tracked_cars = {}\n",
    "tracked_people = {}\n",
    "\n",
    "# Función para calcular la distancia entre dos puntos\n",
    "def calculate_distance(box1, box2):\n",
    "    center1 = np.array([(box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2])\n",
    "    center2 = np.array([(box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2])\n",
    "    return np.linalg.norm(center1 - center2)\n",
    "\n",
    "# Inicialización de la ventana y reproducción de frames\n",
    "for result in results_stream:\n",
    "    frame = result.orig_img\n",
    "    frame_count += 1\n",
    "\n",
    "    # Detección de coches y personas en el frame\n",
    "    if result.boxes is not None:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            label = model_general.names[int(box.cls)]\n",
    "            confidence = box.conf.item()\n",
    "\n",
    "            # Mostrar solo coches y personas\n",
    "            if label == 'car':\n",
    "                # Comprobar si ya existe el coche en el seguimiento\n",
    "                identifier = None\n",
    "                for id, (prev_box, _) in tracked_cars.items():\n",
    "                    if calculate_distance((x1, y1, x2, y2), prev_box) < 50:  # Umbral de distancia\n",
    "                        identifier = id\n",
    "                        break\n",
    "\n",
    "                if identifier is None:\n",
    "                    identifier = f\"car_{total_cars + 1}\"\n",
    "                    total_cars += 1\n",
    "                tracked_cars[identifier] = ((x1, y1, x2, y2), confidence)\n",
    "\n",
    "                text = f\"{label} {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                # Guardar resultados en la lista\n",
    "                results_list.append({\n",
    "                    'frame': frame_count,\n",
    "                    'tipo_objeto': label,\n",
    "                    'confianza': confidence,\n",
    "                    'identificador_tracking': identifier,\n",
    "                    'x1': x1,\n",
    "                    'y1': y1,\n",
    "                    'x2': x2,\n",
    "                    'y2': y2,\n",
    "                    'matricula_en_su_caso': None,\n",
    "                    'confianza_matricula': None,\n",
    "                    'mx1': None,\n",
    "                    'my1': None,\n",
    "                    'mx2': None,\n",
    "                    'my2': None,\n",
    "                    'texto_matricula': None\n",
    "                })\n",
    "\n",
    "            elif label == 'person':\n",
    "                # Comprobar si ya existe la persona en el seguimiento\n",
    "                identifier = None\n",
    "                for id, (prev_box, _) in tracked_people.items():\n",
    "                    if calculate_distance((x1, y1, x2, y2), prev_box) < 50:  # Umbral de distancia\n",
    "                        identifier = id\n",
    "                        break\n",
    "\n",
    "                if identifier is None:\n",
    "                    identifier = f\"person_{total_people + 1}\"\n",
    "                    total_people += 1\n",
    "                tracked_people[identifier] = ((x1, y1, x2, y2), confidence)\n",
    "\n",
    "                text = f\"{label} {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "                # Guardar resultados en la lista\n",
    "                results_list.append({\n",
    "                    'frame': frame_count,\n",
    "                    'tipo_objeto': label,\n",
    "                    'confianza': confidence,\n",
    "                    'identificador_tracking': identifier,\n",
    "                    'x1': x1,\n",
    "                    'y1': y1,\n",
    "                    'x2': x2,\n",
    "                    'y2': y2,\n",
    "                    'matricula_en_su_caso': None,\n",
    "                    'confianza_matricula': None,\n",
    "                    'mx1': None,\n",
    "                    'my1': None,\n",
    "                    'mx2': None,\n",
    "                    'my2': None,\n",
    "                    'texto_matricula': None\n",
    "                })\n",
    "\n",
    "    # Detección de matrículas\n",
    "    results_plates = model_plates(frame)\n",
    "    for result_plates in results_plates:\n",
    "        if result_plates.boxes is not None:\n",
    "            for box in result_plates.boxes:\n",
    "                mx1, my1, mx2, my2 = map(int, box.xyxy[0])\n",
    "                plate_region = frame[my1:my2, mx1:mx2]\n",
    "\n",
    "                # Usar EasyOCR para leer el texto de la matrícula\n",
    "                results = reader.readtext(plate_region)\n",
    "                plate_text = \" \".join([text for (_, text, _) in results])\n",
    "\n",
    "                # Mostrar la matrícula\n",
    "                text_plate = f\"Matricula: {plate_text.strip()}\"\n",
    "                cv2.rectangle(frame, (mx1, my1), (mx2, my2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, text_plate, (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Actualizar la lista con la información de la matrícula\n",
    "                for res in results_list:\n",
    "                    if res['frame'] == frame_count and res['tipo_objeto'] == 'car':\n",
    "                        res.update({\n",
    "                            'matricula_en_su_caso': plate_text.strip(),\n",
    "                            'confianza_matricula': None,\n",
    "                            'mx1': mx1,\n",
    "                            'my1': my1,\n",
    "                            'mx2': mx2,\n",
    "                            'my2': my2,\n",
    "                            'texto_matricula': text_plate.strip()\n",
    "                        })\n",
    "                        break\n",
    "\n",
    "    # Redimensionar el frame y mostrarlo\n",
    "    frame_resized = cv2.resize(frame, (960, 540))\n",
    "    cv2.imshow(\"Video Resized\", frame_resized)\n",
    "\n",
    "    # Detener la ejecución si se presiona la tecla Escape\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "df = pd.DataFrame(results_list)\n",
    "df.to_csv('resultados_deteccion.csv', index=False)\n",
    "\n",
    "# Mostrar el total de coches y personas detectados\n",
    "print(f'Total de coches detectados: {total_cars}')\n",
    "print(f'Total de personas detectadas: {total_people}')\n",
    "\n",
    "# Finalizar la ventana de visualización\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
